{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wtais\\Anaconda3\\envs\\hackthewind\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "n_samples = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.rint(x_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.48627451, 0.99215686,\n",
       "        1.        , 0.24705882, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37647059, 0.95686275, 0.98431373,\n",
       "        0.99215686, 0.24313725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.49803922, 0.98431373, 0.98431373,\n",
       "        0.99215686, 0.24313725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26666667, 0.9254902 , 0.98431373, 0.82745098,\n",
       "        0.12156863, 0.03137255, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23529412, 0.89411765, 0.98431373, 0.98431373, 0.36862745,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.60784314, 0.99215686, 0.99215686, 0.74117647, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07843137,\n",
       "        0.99215686, 0.98431373, 0.92156863, 0.25882353, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1254902 , 0.80392157,\n",
       "        0.99215686, 0.98431373, 0.49411765, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40784314, 0.98431373,\n",
       "        0.99215686, 0.72156863, 0.05882353, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31372549, 0.94117647, 0.98431373,\n",
       "        0.75686275, 0.09019608, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1254902 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.62352941, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.59215686, 0.98431373, 0.98431373, 0.98431373,\n",
       "        0.15294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18823529, 0.86666667, 0.98431373, 0.98431373, 0.6745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.91764706, 0.98431373, 0.98431373, 0.76862745, 0.04705882,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99215686, 0.98431373, 0.98431373, 0.34901961, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.62352941,\n",
       "        1.        , 0.99215686, 0.99215686, 0.12156863, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18823529, 0.89411765,\n",
       "        0.99215686, 0.96862745, 0.54901961, 0.03137255, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25098039, 0.98431373,\n",
       "        0.99215686, 0.8627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25098039, 0.98431373,\n",
       "        0.99215686, 0.8627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09411765, 0.75686275,\n",
       "        0.99215686, 0.8627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3],cmap='gray')\n",
    "plt.title(y_train[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "images_flat = tf.contrib.layers.flatten(x)\n",
    "hidden_layer_1 = tf.contrib.layers.fully_connected(images_flat, 512, tf.nn.relu)\n",
    "y = tf.contrib.layers.fully_connected(hidden_layer_1, 10, tf.nn.relu)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode categorical labels\n",
    "y_train_cat = np.zeros([len(y_train),10])\n",
    "for indx, i in enumerate(y_train):\n",
    "    y_train_cat[indx,i] = 1\n",
    "    \n",
    "y_test_cat = np.zeros([len(y_test),10])\n",
    "for indx, i in enumerate(y_test):\n",
    "    y_test_cat[indx,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  5 ; loss =  2.0465987\n",
      "Step  10 ; loss =  1.6303654\n",
      "Step  15 ; loss =  1.3492438\n",
      "Step  20 ; loss =  1.0896782\n",
      "Step  25 ; loss =  1.0061388\n",
      "Step  30 ; loss =  0.82592356\n",
      "Step  35 ; loss =  0.7197891\n",
      "Step  40 ; loss =  0.64392585\n",
      "Step  45 ; loss =  0.6409801\n",
      "Step  50 ; loss =  0.5822742\n",
      "Step  55 ; loss =  0.5309977\n",
      "Step  60 ; loss =  0.52393115\n",
      "Step  65 ; loss =  0.61557597\n",
      "Step  70 ; loss =  0.50641316\n",
      "Step  75 ; loss =  0.52712023\n",
      "Step  80 ; loss =  0.5428428\n",
      "Step  85 ; loss =  0.49339354\n",
      "Step  90 ; loss =  0.52103823\n",
      "Step  95 ; loss =  0.34304821\n",
      "Step  100 ; loss =  0.38443625\n",
      "Step  105 ; loss =  0.41707224\n",
      "Step  110 ; loss =  0.46352255\n",
      "Step  115 ; loss =  0.3781092\n",
      "Step  120 ; loss =  0.4218219\n",
      "Step  125 ; loss =  0.35569167\n",
      "Step  130 ; loss =  0.43509874\n",
      "Step  135 ; loss =  0.3496038\n",
      "Step  140 ; loss =  0.36138055\n",
      "Step  145 ; loss =  0.4533692\n",
      "Step  150 ; loss =  0.41051176\n",
      "Step  155 ; loss =  0.3553767\n",
      "Step  160 ; loss =  0.33013976\n",
      "Step  165 ; loss =  0.39325637\n",
      "Step  170 ; loss =  0.42127115\n",
      "Step  175 ; loss =  0.33200493\n",
      "Step  180 ; loss =  0.33912504\n",
      "Step  185 ; loss =  0.28400725\n",
      "Step  190 ; loss =  0.33523464\n",
      "Step  195 ; loss =  0.31890085\n",
      "Step  200 ; loss =  0.32023743\n",
      "Step  205 ; loss =  0.36371133\n",
      "Step  210 ; loss =  0.30043352\n",
      "Step  215 ; loss =  0.3275862\n",
      "Step  220 ; loss =  0.29263657\n",
      "Step  225 ; loss =  0.3689381\n",
      "Step  230 ; loss =  0.29360354\n",
      "Step  235 ; loss =  0.3515179\n",
      "Step  240 ; loss =  0.29972783\n",
      "Step  245 ; loss =  0.3097974\n",
      "Step  250 ; loss =  0.3200917\n",
      "Step  255 ; loss =  0.3325395\n",
      "Step  260 ; loss =  0.26936623\n",
      "Step  265 ; loss =  0.28923488\n",
      "Step  270 ; loss =  0.3691434\n",
      "Step  275 ; loss =  0.21124242\n",
      "Step  280 ; loss =  0.3111188\n",
      "Step  285 ; loss =  0.3073199\n",
      "Step  290 ; loss =  0.33250913\n",
      "Step  295 ; loss =  0.25569603\n",
      "Step  300 ; loss =  0.33660915\n",
      "Step  305 ; loss =  0.22747105\n",
      "Step  310 ; loss =  0.25307316\n",
      "Step  315 ; loss =  0.40472367\n",
      "Step  320 ; loss =  0.30297023\n",
      "Step  325 ; loss =  0.31871632\n",
      "Step  330 ; loss =  0.3292525\n",
      "Step  335 ; loss =  0.31462702\n",
      "Step  340 ; loss =  0.21069811\n",
      "Step  345 ; loss =  0.22007324\n",
      "Step  350 ; loss =  0.23678309\n",
      "Step  355 ; loss =  0.21370722\n",
      "Step  360 ; loss =  0.26955545\n",
      "Step  365 ; loss =  0.29147786\n",
      "Step  370 ; loss =  0.34398177\n",
      "Step  375 ; loss =  0.34186783\n",
      "Step  380 ; loss =  0.293991\n",
      "Step  385 ; loss =  0.21513571\n",
      "Step  390 ; loss =  0.3697225\n",
      "Step  395 ; loss =  0.2619198\n",
      "Step  400 ; loss =  0.23098525\n",
      "Step  405 ; loss =  0.2943075\n",
      "Step  410 ; loss =  0.21984589\n",
      "Step  415 ; loss =  0.27006367\n",
      "Step  420 ; loss =  0.29088798\n",
      "Step  425 ; loss =  0.31367645\n",
      "Step  430 ; loss =  0.25361726\n",
      "Step  435 ; loss =  0.29022688\n",
      "Step  440 ; loss =  0.20122333\n",
      "Step  445 ; loss =  0.2997727\n",
      "Step  450 ; loss =  0.24749583\n",
      "Step  455 ; loss =  0.26125434\n",
      "Step  460 ; loss =  0.23103146\n",
      "Step  465 ; loss =  0.22906743\n",
      "Step  470 ; loss =  0.29555684\n",
      "Step  475 ; loss =  0.23704144\n",
      "Step  480 ; loss =  0.24014704\n",
      "Step  485 ; loss =  0.18910299\n",
      "Step  490 ; loss =  0.26075518\n",
      "Step  495 ; loss =  0.22366528\n",
      "Step  500 ; loss =  0.25994405\n",
      "Step  505 ; loss =  0.24430272\n",
      "Step  510 ; loss =  0.2606266\n",
      "Step  515 ; loss =  0.2874584\n",
      "Step  520 ; loss =  0.2287208\n",
      "Step  525 ; loss =  0.23909165\n",
      "Step  530 ; loss =  0.21021342\n",
      "Step  535 ; loss =  0.26687098\n",
      "Step  540 ; loss =  0.24053523\n",
      "Step  545 ; loss =  0.25597003\n",
      "Step  550 ; loss =  0.25436485\n",
      "Step  555 ; loss =  0.27279052\n",
      "Step  560 ; loss =  0.26386777\n",
      "Step  565 ; loss =  0.25667253\n",
      "Step  570 ; loss =  0.21244252\n",
      "Step  575 ; loss =  0.25721872\n",
      "Step  580 ; loss =  0.21401784\n",
      "Step  585 ; loss =  0.24154861\n",
      "Step  590 ; loss =  0.23418747\n",
      "Step  595 ; loss =  0.23951718\n",
      "Step  600 ; loss =  0.22218075\n",
      "Step  605 ; loss =  0.27192506\n",
      "Step  610 ; loss =  0.20115826\n",
      "Step  615 ; loss =  0.17779177\n",
      "Step  620 ; loss =  0.20972216\n",
      "Step  625 ; loss =  0.2325519\n",
      "Step  630 ; loss =  0.31279004\n",
      "Step  635 ; loss =  0.20352401\n",
      "Step  640 ; loss =  0.20705932\n",
      "Step  645 ; loss =  0.22644284\n",
      "Step  650 ; loss =  0.19063361\n",
      "Step  655 ; loss =  0.15381098\n",
      "Step  660 ; loss =  0.2109571\n",
      "Step  665 ; loss =  0.21760027\n",
      "Step  670 ; loss =  0.25708362\n",
      "Step  675 ; loss =  0.31167746\n",
      "Step  680 ; loss =  0.24672356\n",
      "Step  685 ; loss =  0.2200192\n",
      "Step  690 ; loss =  0.20608646\n",
      "Step  695 ; loss =  0.23266849\n",
      "Step  700 ; loss =  0.22941272\n",
      "Step  705 ; loss =  0.21562426\n",
      "Step  710 ; loss =  0.23209058\n",
      "Step  715 ; loss =  0.22893311\n",
      "Step  720 ; loss =  0.24835414\n",
      "Step  725 ; loss =  0.2872943\n",
      "Step  730 ; loss =  0.24850342\n",
      "Step  735 ; loss =  0.18609041\n",
      "Step  740 ; loss =  0.24395065\n",
      "Step  745 ; loss =  0.18439463\n",
      "Step  750 ; loss =  0.14706151\n",
      "Step  755 ; loss =  0.19755732\n",
      "Step  760 ; loss =  0.21881032\n",
      "Step  765 ; loss =  0.19407313\n",
      "Step  770 ; loss =  0.20758717\n",
      "Step  775 ; loss =  0.19678678\n",
      "Step  780 ; loss =  0.18025546\n",
      "Step  785 ; loss =  0.17071195\n",
      "Step  790 ; loss =  0.21577619\n",
      "Step  795 ; loss =  0.18609427\n",
      "Step  800 ; loss =  0.24469934\n",
      "Step  805 ; loss =  0.18981211\n",
      "Step  810 ; loss =  0.17389594\n",
      "Step  815 ; loss =  0.1776132\n",
      "Step  820 ; loss =  0.2272582\n",
      "Step  825 ; loss =  0.21907003\n",
      "Step  830 ; loss =  0.14110121\n",
      "Step  835 ; loss =  0.19769742\n",
      "Step  840 ; loss =  0.20378265\n",
      "Step  845 ; loss =  0.25146416\n",
      "Step  850 ; loss =  0.15586007\n",
      "Step  855 ; loss =  0.19245368\n",
      "Step  860 ; loss =  0.17644748\n",
      "Step  865 ; loss =  0.24684963\n",
      "Step  870 ; loss =  0.1524117\n",
      "Step  875 ; loss =  0.19665003\n",
      "Step  880 ; loss =  0.17543666\n",
      "Step  885 ; loss =  0.2140212\n",
      "Step  890 ; loss =  0.18122712\n",
      "Step  895 ; loss =  0.15737109\n",
      "Step  900 ; loss =  0.2374662\n",
      "Step  905 ; loss =  0.22122592\n",
      "Step  910 ; loss =  0.18803781\n",
      "Step  915 ; loss =  0.1775406\n",
      "Step  920 ; loss =  0.2026554\n",
      "Step  925 ; loss =  0.20154975\n",
      "Step  930 ; loss =  0.26863325\n",
      "Step  935 ; loss =  0.22393364\n",
      "Step  940 ; loss =  0.18805331\n",
      "Step  945 ; loss =  0.22230397\n",
      "Step  950 ; loss =  0.1937493\n",
      "Step  955 ; loss =  0.18052241\n",
      "Step  960 ; loss =  0.15058765\n",
      "Step  965 ; loss =  0.15385604\n",
      "Step  970 ; loss =  0.16557235\n",
      "Step  975 ; loss =  0.16649102\n",
      "Step  980 ; loss =  0.1731104\n",
      "Step  985 ; loss =  0.20481244\n",
      "Step  990 ; loss =  0.16414586\n",
      "Step  995 ; loss =  0.18802205\n",
      "Step  1000 ; loss =  0.18236284\n",
      "Step  1005 ; loss =  0.11687293\n",
      "Step  1010 ; loss =  0.19818185\n",
      "Step  1015 ; loss =  0.20288686\n",
      "Step  1020 ; loss =  0.15746355\n",
      "Step  1025 ; loss =  0.18493144\n",
      "Step  1030 ; loss =  0.13411845\n",
      "Step  1035 ; loss =  0.22333883\n",
      "Step  1040 ; loss =  0.1633435\n",
      "Step  1045 ; loss =  0.18857382\n",
      "Step  1050 ; loss =  0.19751197\n",
      "Step  1055 ; loss =  0.18967192\n",
      "Step  1060 ; loss =  0.11714288\n",
      "Step  1065 ; loss =  0.236961\n",
      "Step  1070 ; loss =  0.15663359\n",
      "Step  1075 ; loss =  0.1597073\n",
      "Step  1080 ; loss =  0.20742281\n",
      "Step  1085 ; loss =  0.16765854\n",
      "Step  1090 ; loss =  0.17486395\n",
      "Step  1095 ; loss =  0.2272255\n",
      "Step  1100 ; loss =  0.1126901\n",
      "Step  1105 ; loss =  0.19463335\n",
      "Step  1110 ; loss =  0.15404652\n",
      "Step  1115 ; loss =  0.16336697\n",
      "Step  1120 ; loss =  0.1959462\n",
      "Step  1125 ; loss =  0.20109591\n",
      "Step  1130 ; loss =  0.16317874\n",
      "Step  1135 ; loss =  0.12754467\n",
      "Step  1140 ; loss =  0.16890977\n",
      "Step  1145 ; loss =  0.20049198\n",
      "Step  1150 ; loss =  0.21111506\n",
      "Step  1155 ; loss =  0.1895468\n",
      "Step  1160 ; loss =  0.19373521\n",
      "Step  1165 ; loss =  0.23681091\n",
      "Step  1170 ; loss =  0.15793492\n",
      "Step  1175 ; loss =  0.21985397\n",
      "Step  1180 ; loss =  0.14497763\n",
      "Step  1185 ; loss =  0.17937458\n",
      "Step  1190 ; loss =  0.15029335\n",
      "Step  1195 ; loss =  0.23044024\n",
      "Step  1200 ; loss =  0.17882681\n",
      "Step  1205 ; loss =  0.1720246\n",
      "Step  1210 ; loss =  0.20787902\n",
      "Step  1215 ; loss =  0.16189371\n",
      "Step  1220 ; loss =  0.25002098\n",
      "Step  1225 ; loss =  0.205603\n",
      "Step  1230 ; loss =  0.14086239\n",
      "Step  1235 ; loss =  0.1796834\n",
      "Step  1240 ; loss =  0.17529127\n",
      "Step  1245 ; loss =  0.14762886\n",
      "Step  1250 ; loss =  0.17365736\n",
      "Step  1255 ; loss =  0.18168002\n",
      "Step  1260 ; loss =  0.14962073\n",
      "Step  1265 ; loss =  0.16444768\n",
      "Step  1270 ; loss =  0.15593569\n",
      "Step  1275 ; loss =  0.18807156\n",
      "Step  1280 ; loss =  0.097219035\n",
      "Step  1285 ; loss =  0.21280812\n",
      "Step  1290 ; loss =  0.1338741\n",
      "Step  1295 ; loss =  0.18522125\n",
      "Step  1300 ; loss =  0.17242306\n",
      "Step  1305 ; loss =  0.20879199\n",
      "Step  1310 ; loss =  0.18706767\n",
      "Step  1315 ; loss =  0.19763768\n",
      "Step  1320 ; loss =  0.15298016\n",
      "Step  1325 ; loss =  0.1582584\n",
      "Step  1330 ; loss =  0.1996328\n",
      "Step  1335 ; loss =  0.18938768\n",
      "Step  1340 ; loss =  0.14676346\n",
      "Step  1345 ; loss =  0.19685209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  1350 ; loss =  0.17828831\n",
      "Step  1355 ; loss =  0.19031382\n",
      "Step  1360 ; loss =  0.2042889\n",
      "Step  1365 ; loss =  0.111154966\n",
      "Step  1370 ; loss =  0.14266938\n",
      "Step  1375 ; loss =  0.13745043\n",
      "Step  1380 ; loss =  0.13488661\n",
      "Step  1385 ; loss =  0.17145154\n",
      "Step  1390 ; loss =  0.20528449\n",
      "Step  1395 ; loss =  0.18034211\n",
      "Step  1400 ; loss =  0.17003769\n",
      "Step  1405 ; loss =  0.20312576\n",
      "Step  1410 ; loss =  0.15187009\n",
      "Step  1415 ; loss =  0.120535545\n",
      "Step  1420 ; loss =  0.16397974\n",
      "Step  1425 ; loss =  0.19834723\n",
      "Step  1430 ; loss =  0.15771075\n",
      "Step  1435 ; loss =  0.12640798\n",
      "Step  1440 ; loss =  0.20987375\n",
      "Step  1445 ; loss =  0.15589367\n",
      "Step  1450 ; loss =  0.13314767\n",
      "Step  1455 ; loss =  0.15994081\n",
      "Step  1460 ; loss =  0.17816266\n",
      "Step  1465 ; loss =  0.14705038\n",
      "Step  1470 ; loss =  0.1584097\n",
      "Step  1475 ; loss =  0.16884686\n",
      "Step  1480 ; loss =  0.1684594\n",
      "Step  1485 ; loss =  0.10632135\n",
      "Step  1490 ; loss =  0.19915429\n",
      "Step  1495 ; loss =  0.14697252\n",
      "Step  1500 ; loss =  0.1731834\n",
      "Step  1505 ; loss =  0.11645436\n",
      "Step  1510 ; loss =  0.14980058\n",
      "Step  1515 ; loss =  0.15642832\n",
      "Step  1520 ; loss =  0.17865376\n",
      "Step  1525 ; loss =  0.14554626\n",
      "Step  1530 ; loss =  0.14614443\n",
      "Step  1535 ; loss =  0.15668654\n",
      "Step  1540 ; loss =  0.16805932\n",
      "Step  1545 ; loss =  0.18178937\n",
      "Step  1550 ; loss =  0.14769413\n",
      "Step  1555 ; loss =  0.15339379\n",
      "Step  1560 ; loss =  0.12501816\n",
      "Step  1565 ; loss =  0.1353847\n",
      "Step  1570 ; loss =  0.12729831\n",
      "Step  1575 ; loss =  0.1445154\n",
      "Step  1580 ; loss =  0.120520644\n",
      "Step  1585 ; loss =  0.110731736\n",
      "Step  1590 ; loss =  0.21272443\n",
      "Step  1595 ; loss =  0.1388199\n",
      "Step  1600 ; loss =  0.15198877\n",
      "Step  1605 ; loss =  0.15195075\n",
      "Step  1610 ; loss =  0.16157545\n",
      "Step  1615 ; loss =  0.16769266\n",
      "Step  1620 ; loss =  0.16616386\n",
      "Step  1625 ; loss =  0.118809916\n",
      "Step  1630 ; loss =  0.11420811\n",
      "Step  1635 ; loss =  0.12030445\n",
      "Step  1640 ; loss =  0.1051307\n",
      "Step  1645 ; loss =  0.17169605\n",
      "Step  1650 ; loss =  0.13911319\n",
      "Step  1655 ; loss =  0.165911\n",
      "Step  1660 ; loss =  0.12116975\n",
      "Step  1665 ; loss =  0.15907444\n",
      "Step  1670 ; loss =  0.107293256\n",
      "Step  1675 ; loss =  0.1383367\n",
      "Step  1680 ; loss =  0.23414554\n",
      "Step  1685 ; loss =  0.13714854\n",
      "Step  1690 ; loss =  0.15856877\n",
      "Step  1695 ; loss =  0.15111491\n",
      "Step  1700 ; loss =  0.21086067\n",
      "Step  1705 ; loss =  0.13609903\n",
      "Step  1710 ; loss =  0.1490375\n",
      "Step  1715 ; loss =  0.08137437\n",
      "Step  1720 ; loss =  0.1562688\n",
      "Step  1725 ; loss =  0.14103808\n",
      "Step  1730 ; loss =  0.14240323\n",
      "Step  1735 ; loss =  0.15429579\n",
      "Step  1740 ; loss =  0.1385423\n",
      "Step  1745 ; loss =  0.13870734\n",
      "Step  1750 ; loss =  0.16181317\n",
      "Step  1755 ; loss =  0.15747142\n",
      "Step  1760 ; loss =  0.13616495\n",
      "Step  1765 ; loss =  0.1543508\n",
      "Step  1770 ; loss =  0.16474538\n",
      "Step  1775 ; loss =  0.15836902\n",
      "Step  1780 ; loss =  0.13623601\n",
      "Step  1785 ; loss =  0.14366066\n",
      "Step  1790 ; loss =  0.12282663\n",
      "Step  1795 ; loss =  0.12811361\n",
      "Step  1800 ; loss =  0.103251375\n",
      "Step  1805 ; loss =  0.115000255\n",
      "Step  1810 ; loss =  0.15658662\n",
      "Step  1815 ; loss =  0.17252979\n",
      "Step  1820 ; loss =  0.09490053\n",
      "Step  1825 ; loss =  0.1411604\n",
      "Step  1830 ; loss =  0.13399492\n",
      "Step  1835 ; loss =  0.13446847\n",
      "Step  1840 ; loss =  0.12592158\n",
      "Step  1845 ; loss =  0.17740528\n",
      "Step  1850 ; loss =  0.117022716\n",
      "Step  1855 ; loss =  0.09939998\n",
      "Step  1860 ; loss =  0.12592675\n",
      "Step  1865 ; loss =  0.14370123\n",
      "Step  1870 ; loss =  0.09918833\n",
      "Step  1875 ; loss =  0.1249155\n",
      "Step  1880 ; loss =  0.10783605\n",
      "Step  1885 ; loss =  0.14034198\n",
      "Step  1890 ; loss =  0.16703826\n",
      "Step  1895 ; loss =  0.16110648\n",
      "Step  1900 ; loss =  0.113839544\n",
      "Step  1905 ; loss =  0.13356902\n",
      "Step  1910 ; loss =  0.119641915\n",
      "Step  1915 ; loss =  0.16580784\n",
      "Step  1920 ; loss =  0.13144913\n",
      "Step  1925 ; loss =  0.17728047\n",
      "Step  1930 ; loss =  0.15857384\n",
      "Step  1935 ; loss =  0.12026019\n",
      "Step  1940 ; loss =  0.11363612\n",
      "Step  1945 ; loss =  0.15657638\n",
      "Step  1950 ; loss =  0.1392194\n",
      "Step  1955 ; loss =  0.10348304\n",
      "Step  1960 ; loss =  0.13926856\n",
      "Step  1965 ; loss =  0.11413486\n",
      "Step  1970 ; loss =  0.09947535\n",
      "Step  1975 ; loss =  0.1706118\n",
      "Step  1980 ; loss =  0.09412165\n",
      "Step  1985 ; loss =  0.13554664\n",
      "Step  1990 ; loss =  0.108236074\n",
      "Step  1995 ; loss =  0.13786095\n",
      "Step  2000 ; loss =  0.108053066\n",
      "Step  2005 ; loss =  0.102864146\n",
      "Step  2010 ; loss =  0.12294032\n",
      "Step  2015 ; loss =  0.12798734\n",
      "Step  2020 ; loss =  0.18297113\n",
      "Step  2025 ; loss =  0.10859824\n",
      "Step  2030 ; loss =  0.09474221\n",
      "Step  2035 ; loss =  0.14417104\n",
      "Step  2040 ; loss =  0.1631802\n",
      "Step  2045 ; loss =  0.15215912\n",
      "Step  2050 ; loss =  0.146016\n",
      "Step  2055 ; loss =  0.10734619\n",
      "Step  2060 ; loss =  0.112029575\n",
      "Step  2065 ; loss =  0.14657389\n",
      "Step  2070 ; loss =  0.122905985\n",
      "Step  2075 ; loss =  0.08245865\n",
      "Step  2080 ; loss =  0.13034523\n",
      "Step  2085 ; loss =  0.16473936\n",
      "Step  2090 ; loss =  0.16638078\n",
      "Step  2095 ; loss =  0.14084052\n",
      "Step  2100 ; loss =  0.13979413\n",
      "Step  2105 ; loss =  0.07165917\n",
      "Step  2110 ; loss =  0.1088408\n",
      "Step  2115 ; loss =  0.19753863\n",
      "Step  2120 ; loss =  0.13154641\n",
      "Step  2125 ; loss =  0.0822113\n",
      "Step  2130 ; loss =  0.13807996\n",
      "Step  2135 ; loss =  0.120766155\n",
      "Step  2140 ; loss =  0.13583888\n",
      "Step  2145 ; loss =  0.11115663\n",
      "Step  2150 ; loss =  0.12818706\n",
      "Step  2155 ; loss =  0.090677485\n",
      "Step  2160 ; loss =  0.09586965\n",
      "Step  2165 ; loss =  0.11543439\n",
      "Step  2170 ; loss =  0.12927304\n",
      "Step  2175 ; loss =  0.12969856\n",
      "Step  2180 ; loss =  0.09565409\n",
      "Step  2185 ; loss =  0.13137166\n",
      "Step  2190 ; loss =  0.10128811\n",
      "Step  2195 ; loss =  0.09277752\n",
      "Step  2200 ; loss =  0.09524519\n",
      "Step  2205 ; loss =  0.08746042\n",
      "Step  2210 ; loss =  0.095779546\n",
      "Step  2215 ; loss =  0.14022595\n",
      "Step  2220 ; loss =  0.09506684\n",
      "Step  2225 ; loss =  0.07987772\n",
      "Step  2230 ; loss =  0.14463069\n",
      "Step  2235 ; loss =  0.13625114\n",
      "Step  2240 ; loss =  0.061973535\n",
      "Step  2245 ; loss =  0.09287095\n",
      "Step  2250 ; loss =  0.13621935\n",
      "Step  2255 ; loss =  0.1336053\n",
      "Step  2260 ; loss =  0.09979731\n",
      "Step  2265 ; loss =  0.10443265\n",
      "Step  2270 ; loss =  0.116328456\n",
      "Step  2275 ; loss =  0.09132564\n",
      "Step  2280 ; loss =  0.089885876\n",
      "Step  2285 ; loss =  0.15430203\n",
      "Step  2290 ; loss =  0.08083797\n",
      "Step  2295 ; loss =  0.13667631\n",
      "Step  2300 ; loss =  0.113678336\n",
      "Step  2305 ; loss =  0.13527727\n",
      "Step  2310 ; loss =  0.10928384\n",
      "Step  2315 ; loss =  0.09352983\n",
      "Step  2320 ; loss =  0.12006803\n",
      "Step  2325 ; loss =  0.11955963\n",
      "Step  2330 ; loss =  0.11606366\n",
      "Step  2335 ; loss =  0.11870642\n",
      "Step  2340 ; loss =  0.08971786\n",
      "Step  2345 ; loss =  0.09347683\n",
      "Step  2350 ; loss =  0.1468014\n",
      "Step  2355 ; loss =  0.07694538\n",
      "Step  2360 ; loss =  0.104549594\n",
      "Step  2365 ; loss =  0.11804045\n",
      "Step  2370 ; loss =  0.12217074\n",
      "Step  2375 ; loss =  0.10608882\n",
      "Step  2380 ; loss =  0.12233391\n",
      "Step  2385 ; loss =  0.10258153\n",
      "Step  2390 ; loss =  0.065370165\n",
      "Step  2395 ; loss =  0.10506151\n",
      "Step  2400 ; loss =  0.10473906\n",
      "Step  2405 ; loss =  0.085272595\n",
      "Step  2410 ; loss =  0.09675556\n",
      "Step  2415 ; loss =  0.11094718\n",
      "Step  2420 ; loss =  0.11670078\n",
      "Step  2425 ; loss =  0.11936278\n",
      "Step  2430 ; loss =  0.12316025\n",
      "Step  2435 ; loss =  0.12690608\n",
      "Step  2440 ; loss =  0.13411699\n",
      "Step  2445 ; loss =  0.08440192\n",
      "Step  2450 ; loss =  0.18328996\n",
      "Step  2455 ; loss =  0.11403689\n",
      "Step  2460 ; loss =  0.14442441\n",
      "Step  2465 ; loss =  0.084346496\n",
      "Step  2470 ; loss =  0.13757277\n",
      "Step  2475 ; loss =  0.14164738\n",
      "Step  2480 ; loss =  0.11675809\n",
      "Step  2485 ; loss =  0.11536799\n",
      "Step  2490 ; loss =  0.09533351\n",
      "Step  2495 ; loss =  0.16741592\n",
      "Step  2500 ; loss =  0.12499937\n",
      "Step  2505 ; loss =  0.09994782\n",
      "Step  2510 ; loss =  0.13647816\n",
      "Step  2515 ; loss =  0.1535059\n",
      "Step  2520 ; loss =  0.11273694\n",
      "Step  2525 ; loss =  0.1359076\n",
      "Step  2530 ; loss =  0.09462718\n",
      "Step  2535 ; loss =  0.112623826\n",
      "Step  2540 ; loss =  0.13600336\n",
      "Step  2545 ; loss =  0.16634071\n",
      "Step  2550 ; loss =  0.10107047\n",
      "Step  2555 ; loss =  0.089736804\n",
      "Step  2560 ; loss =  0.077257596\n",
      "Step  2565 ; loss =  0.11289726\n",
      "Step  2570 ; loss =  0.079144396\n",
      "Step  2575 ; loss =  0.07981834\n",
      "Step  2580 ; loss =  0.12512273\n",
      "Step  2585 ; loss =  0.14514574\n",
      "Step  2590 ; loss =  0.088116325\n",
      "Step  2595 ; loss =  0.1377103\n",
      "Step  2600 ; loss =  0.08129906\n",
      "Step  2605 ; loss =  0.09210548\n",
      "Step  2610 ; loss =  0.07223194\n",
      "Step  2615 ; loss =  0.14732446\n",
      "Step  2620 ; loss =  0.10314202\n",
      "Step  2625 ; loss =  0.09527048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  2630 ; loss =  0.11884177\n",
      "Step  2635 ; loss =  0.14635187\n",
      "Step  2640 ; loss =  0.089929014\n",
      "Step  2645 ; loss =  0.17161219\n",
      "Step  2650 ; loss =  0.08146466\n",
      "Step  2655 ; loss =  0.121815756\n",
      "Step  2660 ; loss =  0.11463358\n",
      "Step  2665 ; loss =  0.14308117\n",
      "Step  2670 ; loss =  0.13773173\n",
      "Step  2675 ; loss =  0.10635933\n",
      "Step  2680 ; loss =  0.089521624\n",
      "Step  2685 ; loss =  0.1254117\n",
      "Step  2690 ; loss =  0.1037066\n",
      "Step  2695 ; loss =  0.07501176\n",
      "Step  2700 ; loss =  0.06857918\n",
      "Step  2705 ; loss =  0.11916508\n",
      "Step  2710 ; loss =  0.091084056\n",
      "Step  2715 ; loss =  0.09148526\n",
      "Step  2720 ; loss =  0.11466105\n",
      "Step  2725 ; loss =  0.058650613\n",
      "Step  2730 ; loss =  0.1026623\n",
      "Step  2735 ; loss =  0.092096314\n",
      "Step  2740 ; loss =  0.09015337\n",
      "Step  2745 ; loss =  0.09148603\n",
      "Step  2750 ; loss =  0.0891732\n",
      "Step  2755 ; loss =  0.13788915\n",
      "Step  2760 ; loss =  0.11350227\n",
      "Step  2765 ; loss =  0.12881635\n",
      "Step  2770 ; loss =  0.114633486\n",
      "Step  2775 ; loss =  0.099811286\n",
      "Step  2780 ; loss =  0.07238847\n",
      "Step  2785 ; loss =  0.09730318\n",
      "Step  2790 ; loss =  0.08432228\n",
      "Step  2795 ; loss =  0.17213054\n",
      "Step  2800 ; loss =  0.10705298\n",
      "Step  2805 ; loss =  0.11491907\n",
      "Step  2810 ; loss =  0.1041797\n",
      "Step  2815 ; loss =  0.12882806\n",
      "Step  2820 ; loss =  0.07306634\n",
      "Step  2825 ; loss =  0.071156144\n",
      "Step  2830 ; loss =  0.12173687\n",
      "Step  2835 ; loss =  0.12132929\n",
      "Step  2840 ; loss =  0.1433503\n",
      "Step  2845 ; loss =  0.104817554\n",
      "Step  2850 ; loss =  0.12162257\n",
      "Step  2855 ; loss =  0.109525196\n",
      "Step  2860 ; loss =  0.07292093\n",
      "Step  2865 ; loss =  0.080782026\n",
      "Step  2870 ; loss =  0.12678769\n",
      "Step  2875 ; loss =  0.10813337\n",
      "Step  2880 ; loss =  0.11041112\n",
      "Step  2885 ; loss =  0.101783484\n",
      "Step  2890 ; loss =  0.08176604\n",
      "Step  2895 ; loss =  0.08996906\n",
      "Step  2900 ; loss =  0.095964506\n",
      "Step  2905 ; loss =  0.14615496\n",
      "Step  2910 ; loss =  0.104454115\n",
      "Step  2915 ; loss =  0.14148389\n",
      "Step  2920 ; loss =  0.067706\n",
      "Step  2925 ; loss =  0.089870214\n",
      "Step  2930 ; loss =  0.09032461\n",
      "Step  2935 ; loss =  0.078186534\n",
      "Step  2940 ; loss =  0.06054245\n",
      "Step  2945 ; loss =  0.13314404\n",
      "Step  2950 ; loss =  0.08371317\n",
      "Step  2955 ; loss =  0.09561834\n",
      "Step  2960 ; loss =  0.08632039\n",
      "Step  2965 ; loss =  0.11310595\n",
      "Step  2970 ; loss =  0.066227406\n",
      "Step  2975 ; loss =  0.12883078\n",
      "Step  2980 ; loss =  0.1259955\n",
      "Step  2985 ; loss =  0.0873655\n",
      "Step  2990 ; loss =  0.10374713\n",
      "Step  2995 ; loss =  0.08438693\n",
      "Step  3000 ; loss =  0.096035786\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "batch_size = 300\n",
    "loss_batch = []\n",
    "\n",
    "# Mini-batch gradient descent\n",
    "for epoch in range(3000):\n",
    "    rand_index = np.random.choice(n_samples, size=batch_size)\n",
    "    x_batch = x_train[rand_index,:]\n",
    "    y_batch = y_train_cat[rand_index]\n",
    "    sess.run(train_step, feed_dict={x: x_batch, y_: y_batch})\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        temp_loss = sess.run(loss, feed_dict={x: x_batch, y_:y_batch})\n",
    "        loss_batch.append(temp_loss)\n",
    "        print('Step ', str(epoch+1), '; loss = ', temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_batch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of predictions :  0.8099382692526635\n",
      "Accuracy of predictions :  0.9664\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = sess.run([tf.argmax(y, 1)], feed_dict={x: x_test})[0]\n",
    "test_rmse = np.sqrt(np.mean((y_pred - y_test)**2))\n",
    "test_accuracy = (y_test == y_pred).mean()\n",
    "print('RMSE of predictions : ', test_rmse)\n",
    "print('Accuracy of predictions : ', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
